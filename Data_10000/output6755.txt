{"kind": "Listing", "data": {"after": "t1_jcd9ohl", "dist": 25, "modhash": null, "geo_filter": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qh94", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "Jeg spurte en AI om \u00e5 lage et bilde: \"Erna Solberg riding on a norwegian tank to valhalla\" absolutt ikke skuffet.", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "norge", "link_author": "Nickstranger", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcwbb5q", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 31, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jcvpjbd", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "*You ARE the ~~brute squad~~ army*", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;em&gt;You ARE the &lt;del&gt;brute squad&lt;/del&gt; army&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11vp3k6", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/norge/comments/11vp3k6/jeg_spurte_en_ai_om_\u00e5_lage_et_bilde_erna_solberg/jcwbb5q/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/norge/comments/11vp3k6/jeg_spurte_en_ai_om_\u00e5_lage_et_bilde_erna_solberg/", "name": "t1_jcwbb5q", "author_flair_template_id": null, "subreddit_name_prefixed": "r/norge", "author_flair_text": null, "treatment_tags": [], "created": 1679275692.0, "created_utc": 1679275692.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://i.redd.it/neec0jn5ypoa1.png"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "Trouble setting up 4bit LLaMA w/ webUI", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "sim_guy1", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcuce15", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 6, "can_mod_post": false, "send_replies": true, "parent_id": "t3_11v81dh", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "&gt; \"ValueError: Tokenizer class LLaMATokenizer does not exist or is not currently imported\"\n\nYeah, that's a known bug. Check the file \"tokenizer_config.json\" in the llama models folder. You need to change \"tokenizer_class\" to \"LlamaTokenizer\" because of some code changes. The models on huggingface aren't updated.\n\nYou could also try my docker guide, see if that goes easier: https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;&amp;quot;ValueError: Tokenizer class LLaMATokenizer does not exist or is not currently imported&amp;quot;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yeah, that&amp;#39;s a known bug. Check the file &amp;quot;tokenizer_config.json&amp;quot; in the llama models folder. You need to change &amp;quot;tokenizer_class&amp;quot; to &amp;quot;LlamaTokenizer&amp;quot; because of some code changes. The models on huggingface aren&amp;#39;t updated.&lt;/p&gt;\n\n&lt;p&gt;You could also try my docker guide, see if that goes easier: &lt;a href=\"https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/\"&gt;https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11v81dh", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11v81dh/trouble_setting_up_4bit_llama_w_webui/jcuce15/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11v81dh/trouble_setting_up_4bit_llama_w_webui/", "name": "t1_jcuce15", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679245449.0, "created_utc": 1679245449.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11v81dh/trouble_setting_up_4bit_llama_w_webui/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jctjabt", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jctdq8u", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "I haven't used gradio, but I guess it timed out or lost connection? Maybe try restarting the docker image.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I haven&amp;#39;t used gradio, but I guess it timed out or lost connection? Maybe try restarting the docker image.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jctjabt/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jctjabt", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679232659.0, "created_utc": 1679232659.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_7hqomg", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "Did the system drastically change in the last few hours?", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "ChatGPT", "link_author": "Obsidian_Ice_king", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcs0h3u", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 3, "can_mod_post": false, "send_replies": true, "parent_id": "t3_11v8pwv", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "I suspect they have different models that they swap between, some having lighter computing requirements. Reason I say that is that sometimes I see drastic change in level of understanding in a post or two, then it suddenly is back to more normal levels. \n\nThis is with the API, but I assume it's similar for the chatgpt page too.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I suspect they have different models that they swap between, some having lighter computing requirements. Reason I say that is that sometimes I see drastic change in level of understanding in a post or two, then it suddenly is back to more normal levels. &lt;/p&gt;\n\n&lt;p&gt;This is with the API, but I assume it&amp;#39;s similar for the chatgpt page too.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11v8pwv", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/ChatGPT/comments/11v8pwv/did_the_system_drastically_change_in_the_last_few/jcs0h3u/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/ChatGPT/comments/11v8pwv/did_the_system_drastically_change_in_the_last_few/", "name": "t1_jcs0h3u", "author_flair_template_id": null, "subreddit_name_prefixed": "r/ChatGPT", "author_flair_text": null, "treatment_tags": [], "created": 1679193808.0, "created_utc": 1679193808.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/ChatGPT/comments/11v8pwv/did_the_system_drastically_change_in_the_last_few/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[D] Totally Open Alternatives to ChatGPT", "mod_reason_by": null, "banned_by": null, "ups": 8, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "MachineLearning", "link_author": "KingsmanVince", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcpqdnz", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": false, "author": "TheTerrasque", "num_comments": 74, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jcp4z19", "score": 8, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "https://huggingface.co/bigscience/bloomz\n\nEdit: and regarding petals, what do you presume inferencing is?", "edited": 1679171119.0, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://huggingface.co/bigscience/bloomz\"&gt;https://huggingface.co/bigscience/bloomz&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Edit: and regarding petals, what do you presume inferencing is?&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11uk8ti", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/MachineLearning/comments/11uk8ti/d_totally_open_alternatives_to_chatgpt/jcpqdnz/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/MachineLearning/comments/11uk8ti/d_totally_open_alternatives_to_chatgpt/", "name": "t1_jcpqdnz", "author_flair_template_id": null, "subreddit_name_prefixed": "r/MachineLearning", "author_flair_text": null, "treatment_tags": [], "created": 1679157600.0, "created_utc": 1679157600.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/MachineLearning/comments/11uk8ti/d_totally_open_alternatives_to_chatgpt/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jclpj5r", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jclaj6f", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "Cool, but strange.. Anyway, I'll make a new release later today or tomorrow with all the new changes that has come in.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Cool, but strange.. Anyway, I&amp;#39;ll make a new release later today or tomorrow with all the new changes that has come in.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jclpj5r/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jclpj5r", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679080030.0, "created_utc": 1679080030.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "My first impressions with the Alpaca-LoRA combined with llama-7b", "mod_reason_by": null, "banned_by": null, "ups": 2, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "oobabooga1", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcl3g7j", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 23, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jckyawd", "score": 2, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "Right now it doesn't. I'll see if I can get it updated.\n\nEdit: As I only got a 10gb card, it's kinda useless for me until 4bit comes out, so it hasn't been a huge priority. I did get to try it out a bit via https://github.com/antimatter15/alpaca.cpp - and [made an image for it](https://www.reddit.com/r/Oobabooga/comments/11thnh9/my_first_impressions_with_the_alpacalora_combined/jckt10z/) too.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Right now it doesn&amp;#39;t. I&amp;#39;ll see if I can get it updated.&lt;/p&gt;\n\n&lt;p&gt;Edit: As I only got a 10gb card, it&amp;#39;s kinda useless for me until 4bit comes out, so it hasn&amp;#39;t been a huge priority. I did get to try it out a bit via &lt;a href=\"https://github.com/antimatter15/alpaca.cpp\"&gt;https://github.com/antimatter15/alpaca.cpp&lt;/a&gt; - and &lt;a href=\"https://www.reddit.com/r/Oobabooga/comments/11thnh9/my_first_impressions_with_the_alpacalora_combined/jckt10z/\"&gt;made an image for it&lt;/a&gt; too.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11thnh9", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11thnh9/my_first_impressions_with_the_alpacalora_combined/jcl3g7j/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11thnh9/my_first_impressions_with_the_alpacalora_combined/", "name": "t1_jcl3g7j", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679071554.0, "created_utc": 1679071554.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11thnh9/my_first_impressions_with_the_alpacalora_combined/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "My first impressions with the Alpaca-LoRA combined with llama-7b", "mod_reason_by": null, "banned_by": null, "ups": 3, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "oobabooga1", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jckt10z", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 23, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jcjh89d", "score": 3, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "If you have [docker](https://docs.docker.com/desktop/install/windows-install/), I made an image. You can run it like this:\n\n    docker run --rm -it -v C:\\path\\to\\ggml-alpaca-7b-q4.bin:/app/ggml-alpaca-7b-q4.bin terrasque/alpaca.cpp", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you have &lt;a href=\"https://docs.docker.com/desktop/install/windows-install/\"&gt;docker&lt;/a&gt;, I made an image. You can run it like this:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;docker run --rm -it -v C:\\path\\to\\ggml-alpaca-7b-q4.bin:/app/ggml-alpaca-7b-q4.bin terrasque/alpaca.cpp\n&lt;/code&gt;&lt;/pre&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11thnh9", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11thnh9/my_first_impressions_with_the_alpacalora_combined/jckt10z/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11thnh9/my_first_impressions_with_the_alpacalora_combined/", "name": "t1_jckt10z", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679067565.0, "created_utc": 1679067565.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11thnh9/my_first_impressions_with_the_alpacalora_combined/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jckrv5q", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jcklbly", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "Glad to hear! Sadly, I'm in the wrong city, in the wrong country, on the wrong continent for that beer. \n\nI like having things like this in dockers, makes it more predictable and stable, and doesn't mess with anything else on my system. A bit more work to set up, usually, but worth it. \n\nThat it also being a help to others is a fantastic bonus, and makes it all worth it :D", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Glad to hear! Sadly, I&amp;#39;m in the wrong city, in the wrong country, on the wrong continent for that beer. &lt;/p&gt;\n\n&lt;p&gt;I like having things like this in dockers, makes it more predictable and stable, and doesn&amp;#39;t mess with anything else on my system. A bit more work to set up, usually, but worth it. &lt;/p&gt;\n\n&lt;p&gt;That it also being a help to others is a fantastic bonus, and makes it all worth it :D&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jckrv5q/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jckrv5q", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679067111.0, "created_utc": 1679067111.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcjq7a0", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jcjow69", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "Completely on it's own it's pretty bad. There is a [ChatBOT persona](https://www.reddit.com/r/Oobabooga/comments/11qgwui/getting_chatgpt_type_responses_from_llama/) that helps, as it gives instructions and a few examples.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Completely on it&amp;#39;s own it&amp;#39;s pretty bad. There is a &lt;a href=\"https://www.reddit.com/r/Oobabooga/comments/11qgwui/getting_chatgpt_type_responses_from_llama/\"&gt;ChatBOT persona&lt;/a&gt; that helps, as it gives instructions and a few examples.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jcjq7a0/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jcjq7a0", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679047441.0, "created_utc": 1679047441.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcjobe0", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jcjlon9", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "I haven't seen that before, and not sure what would cause it. Maybe the model or model metadata is corrupt? Did you copy over or let it download it?\n\nAlso, Can you try this command in a powershell console?\n\n    docker run --rm -it --gpus all -v $PWD/models:/app/models -v $PWD/characters:/app/characters -p 8889:8889 terrasque/llama-webui:v0.1\n\nThat uses a prebuilt image I uploaded.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I haven&amp;#39;t seen that before, and not sure what would cause it. Maybe the model or model metadata is corrupt? Did you copy over or let it download it?&lt;/p&gt;\n\n&lt;p&gt;Also, Can you try this command in a powershell console?&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;docker run --rm -it --gpus all -v $PWD/models:/app/models -v $PWD/characters:/app/characters -p 8889:8889 terrasque/llama-webui:v0.1\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;That uses a prebuilt image I uploaded.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jcjobe0/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jcjobe0", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679045873.0, "created_utc": 1679045873.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcjevwj", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jcjbtfy", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "Can you try this command in a powershell console?\n\n    docker run --rm -it --gpus all -v $PWD/models:/app/models -v $PWD/characters:/app/characters -p 8889:8889 terrasque/llama-webui:v0.1\n\nThat uses a prebuilt image I just uploaded.\n\nEdit: Mentioned powershell", "edited": 1679037976.0, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can you try this command in a powershell console?&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;docker run --rm -it --gpus all -v $PWD/models:/app/models -v $PWD/characters:/app/characters -p 8889:8889 terrasque/llama-webui:v0.1\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;That uses a prebuilt image I just uploaded.&lt;/p&gt;\n\n&lt;p&gt;Edit: Mentioned powershell&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jcjevwj/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jcjevwj", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679037613.0, "created_utc": 1679037613.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcjdtki", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jciclwr", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "I read somewhere that the 30b and 65b 4bit files on huggingface is broken and the repository owners haven't bothered to fix it. \n\nIf so that would explain it. If you get working 4bit version from somewhere or convert it yourself, you could drop the file in the models folder and it should work.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I read somewhere that the 30b and 65b 4bit files on huggingface is broken and the repository owners haven&amp;#39;t bothered to fix it. &lt;/p&gt;\n\n&lt;p&gt;If so that would explain it. If you get working 4bit version from somewhere or convert it yourself, you could drop the file in the models folder and it should work.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jcjdtki/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jcjdtki", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679036699.0, "created_utc": 1679036699.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcjdks8", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jciugjf", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "From those that have got it working, I've only heard that the output is good.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;From those that have got it working, I&amp;#39;ve only heard that the output is good.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jcjdks8/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jcjdks8", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679036493.0, "created_utc": 1679036493.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcjbmyk", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jcibh3y", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "The versions are locked to before the changes, planning to look at it and update things later today.\n\nDid you download the release file, or use a git clone? \n\nAnd if latter, could you check the top entry of \"git log\"? And do \"git pull\" to get the latest and rebuild again?", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The versions are locked to before the changes, planning to look at it and update things later today.&lt;/p&gt;\n\n&lt;p&gt;Did you download the release file, or use a git clone? &lt;/p&gt;\n\n&lt;p&gt;And if latter, could you check the top entry of &amp;quot;git log&amp;quot;? And do &amp;quot;git pull&amp;quot; to get the latest and rebuild again?&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jcjbmyk/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jcjbmyk", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679034913.0, "created_utc": 1679034913.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcjb7ay", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jciy1e1", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "Only I can think of is if the graphics card isn't available. \n\nFurther up should be the logs of it building the library, could you post that part?\n\nEdit: Can you try this command in a powershell console?\n\n    docker run --rm -it --gpus all -v $PWD/models:/app/models -v $PWD/characters:/app/characters -p 8889:8889 terrasque/llama-webui:v0.1\n\nThat uses a prebuilt image I uploaded.", "edited": 1679045193.0, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Only I can think of is if the graphics card isn&amp;#39;t available. &lt;/p&gt;\n\n&lt;p&gt;Further up should be the logs of it building the library, could you post that part?&lt;/p&gt;\n\n&lt;p&gt;Edit: Can you try this command in a powershell console?&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;docker run --rm -it --gpus all -v $PWD/models:/app/models -v $PWD/characters:/app/characters -p 8889:8889 terrasque/llama-webui:v0.1\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;That uses a prebuilt image I uploaded.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jcjb7ay/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jcjb7ay", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679034556.0, "created_utc": 1679034556.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_7hqomg", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "GPT-4 just changed its message limit to 50 every 4 hours instead of 100", "mod_reason_by": null, "banned_by": null, "ups": 2, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "ChatGPT", "link_author": "majingrim", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jci1a0e", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 870, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jchcsnv", "score": 2, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "I've noticed normal ChatGPT api has been a lot slower and more unstable than normal today, guessing GPT4 uses a lot more resources than anticipated.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve noticed normal ChatGPT api has been a lot slower and more unstable than normal today, guessing GPT4 uses a lot more resources than anticipated.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11t5cfk", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/ChatGPT/comments/11t5cfk/gpt4_just_changed_its_message_limit_to_50_every_4/jci1a0e/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/ChatGPT/comments/11t5cfk/gpt4_just_changed_its_message_limit_to_50_every_4/", "name": "t1_jci1a0e", "author_flair_template_id": null, "subreddit_name_prefixed": "r/ChatGPT", "author_flair_text": null, "treatment_tags": [], "created": 1679010125.0, "created_utc": 1679010125.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://i.redd.it/3ods6qpcv5oa1.png"}}, {"kind": "t1", "data": {"subreddit_id": "t5_81eyvm", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "How to install LLaMA: 8-bit and 4-bit", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "LocalLLaMA", "link_author": "Technical_Leather949", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jchjbgn", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 120, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jcgsicw", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "I've put together a more automated setup, maybe you'll have more luck with that: https://github.com/TheTerrasque/text-generation-webui", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve put together a more automated setup, maybe you&amp;#39;ll have more luck with that: &lt;a href=\"https://github.com/TheTerrasque/text-generation-webui\"&gt;https://github.com/TheTerrasque/text-generation-webui&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11o6o3f", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/LocalLLaMA/comments/11o6o3f/how_to_install_llama_8bit_and_4bit/jchjbgn/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/LocalLLaMA/comments/11o6o3f/how_to_install_llama_8bit_and_4bit/", "name": "t1_jchjbgn", "author_flair_template_id": null, "subreddit_name_prefixed": "r/LocalLLaMA", "author_flair_text": null, "treatment_tags": [], "created": 1679002758.0, "created_utc": 1679002758.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/LocalLLaMA/comments/11o6o3f/how_to_install_llama_8bit_and_4bit/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jchi4jp", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jchh10f", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "look at docker/run.sh - Near the top there's a line saying\n\n    model=\"llama-7b\"\n\nI've tested changing it to 13b and that worked without problem. It will probably work with the 30b and 65b model too, but I haven't tested it.\n\nAfter changing, just close the webui console and run docker_start.bat again, and it should download and load the new model.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;look at docker/run.sh - Near the top there&amp;#39;s a line saying&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;model=&amp;quot;llama-7b&amp;quot;\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;I&amp;#39;ve tested changing it to 13b and that worked without problem. It will probably work with the 30b and 65b model too, but I haven&amp;#39;t tested it.&lt;/p&gt;\n\n&lt;p&gt;After changing, just close the webui console and run docker_start.bat again, and it should download and load the new model.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jchi4jp/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jchi4jp", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1679002279.0, "created_utc": 1679002279.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 2, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcfu67u", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jcfshi3", "score": 2, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "Huh, that's very strange. \n\nAh, here's the reason. https://github.com/qwopqwop200/GPTQ-for-LLaMa/commit/19f1c32c1b57bcb022ddcf77ee7e52987d8871f0\n\nIf you try it again now it'll most likely work. Do \"docker compose build --no-cache\" and it should fetch the new code from GPTQ-for-LLaMa. I'm still rebuilding so I can't say for sure that it fixes it, but from the change log it's what I expected. \n\nI'm going to lock that code repository to a specific version, so I can check that it all works and if needed update things before new versions get pulled in.\n\nEdit: Can confirm it works now, also locked the version of that library.", "edited": 1678980820.0, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Huh, that&amp;#39;s very strange. &lt;/p&gt;\n\n&lt;p&gt;Ah, here&amp;#39;s the reason. &lt;a href=\"https://github.com/qwopqwop200/GPTQ-for-LLaMa/commit/19f1c32c1b57bcb022ddcf77ee7e52987d8871f0\"&gt;https://github.com/qwopqwop200/GPTQ-for-LLaMa/commit/19f1c32c1b57bcb022ddcf77ee7e52987d8871f0&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;If you try it again now it&amp;#39;ll most likely work. Do &amp;quot;docker compose build --no-cache&amp;quot; and it should fetch the new code from GPTQ-for-LLaMa. I&amp;#39;m still rebuilding so I can&amp;#39;t say for sure that it fixes it, but from the change log it&amp;#39;s what I expected. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m going to lock that code repository to a specific version, so I can check that it all works and if needed update things before new versions get pulled in.&lt;/p&gt;\n\n&lt;p&gt;Edit: Can confirm it works now, also locked the version of that library.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jcfu67u/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jcfu67u", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1678979424.0, "created_utc": 1678979424.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "Can someone explain a couple of llama basics to me? 2 kinds of models, 4vs8bit, 7,13,30,65b", "mod_reason_by": null, "banned_by": null, "ups": 2, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "Strooonzo", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jceu0zm", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 11, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jceawzy", "score": 2, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "Maybe you can try https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe you can try &lt;a href=\"https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/\"&gt;https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11rcdws", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11rcdws/can_someone_explain_a_couple_of_llama_basics_to/jceu0zm/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11rcdws/can_someone_explain_a_couple_of_llama_basics_to/", "name": "t1_jceu0zm", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1678960092.0, "created_utc": 1678960092.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11rcdws/can_someone_explain_a_couple_of_llama_basics_to/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[Nvidia] Guide: Getting llama-7b 4bit running in simple(ish?) steps!", "mod_reason_by": null, "banned_by": null, "ups": 1, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "TheTerrasque", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcetyve", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 36, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jceecgg", "score": 1, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "quant_cuda is from https://github.com/qwopqwop200/GPTQ-for-LLaMa, the library needed to run 4bit models. Since you're missing it, it either wasn't installed or failed during installation.\n\nThat shouldn't happen with my docker method, maybe you can try that instead.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": true, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;quant_cuda is from &lt;a href=\"https://github.com/qwopqwop200/GPTQ-for-LLaMa\"&gt;https://github.com/qwopqwop200/GPTQ-for-LLaMa&lt;/a&gt;, the library needed to run 4bit models. Since you&amp;#39;re missing it, it either wasn&amp;#39;t installed or failed during installation.&lt;/p&gt;\n\n&lt;p&gt;That shouldn&amp;#39;t happen with my docker method, maybe you can try that instead.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sbwjx", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/jcetyve/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/", "name": "t1_jcetyve", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1678960042.0, "created_utc": 1678960042.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11sbwjx/nvidia_guide_getting_llama7b_4bit_running_in/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qh94", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "[ Removed by Reddit ]", "mod_reason_by": null, "banned_by": null, "ups": 42, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "norge", "link_author": "mcnikko", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jces76z", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": false, "author": "TheTerrasque", "num_comments": 107, "can_mod_post": false, "send_replies": true, "parent_id": "t3_11sms50", "score": 42, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "Pr\u00f8vd finn.no? De har s\u00e5nn grei \"fiks ferdig\" ting.", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Pr\u00f8vd finn.no? De har s\u00e5nn grei &amp;quot;fiks ferdig&amp;quot; ting.&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11sms50", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/norge/comments/11sms50/removed_by_reddit/jces76z/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/norge/comments/11sms50/removed_by_reddit/", "name": "t1_jces76z", "author_flair_template_id": null, "subreddit_name_prefixed": "r/norge", "author_flair_text": null, "treatment_tags": [], "created": 1678958539.0, "created_utc": 1678958539.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/norge/comments/11sms50/removed_by_reddit/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_80tprv", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "Can someone explain a couple of llama basics to me? 2 kinds of models, 4vs8bit, 7,13,30,65b", "mod_reason_by": null, "banned_by": null, "ups": 2, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "Oobabooga", "link_author": "Strooonzo", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jceap2m", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": true, "author": "TheTerrasque", "num_comments": 11, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jce50ec", "score": 2, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "https://huggingface.co/decapoda-research", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://huggingface.co/decapoda-research\"&gt;https://huggingface.co/decapoda-research&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11rcdws", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/Oobabooga/comments/11rcdws/can_someone_explain_a_couple_of_llama_basics_to/jceap2m/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/Oobabooga/comments/11rcdws/can_someone_explain_a_couple_of_llama_basics_to/", "name": "t1_jceap2m", "author_flair_template_id": null, "subreddit_name_prefixed": "r/Oobabooga", "author_flair_text": null, "treatment_tags": [], "created": 1678944024.0, "created_utc": 1678944024.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://www.reddit.com/r/Oobabooga/comments/11rcdws/can_someone_explain_a_couple_of_llama_basics_to/"}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qh0s", "approved_at_utc": null, "author_is_blocked": false, "comment_type": null, "link_title": "Tech Support", "mod_reason_by": null, "banned_by": null, "ups": 9, "num_reports": null, "author_flair_type": "text", "total_awards_received": 0, "subreddit": "comics", "link_author": "But_a_Jape", "likes": null, "replies": "", "user_reports": [], "saved": false, "id": "jcd9ohl", "banned_at_utc": null, "mod_reason_title": null, "gilded": 0, "archived": false, "collapsed_reason_code": null, "no_follow": false, "author": "TheTerrasque", "num_comments": 122, "can_mod_post": false, "send_replies": true, "parent_id": "t1_jcd86ad", "score": 9, "author_fullname": "t2_9uv8v", "over_18": false, "report_reasons": null, "removal_reason": null, "approved_by": null, "controversiality": 0, "body": "&gt; I didn\u2019t however sell them stuff they didn\u2019t need.\n\nWell fuck me sideways, more or less same story here. Highest average solved cases daily, shortest phone calls, made some tools to more quickly and effective find common issues... But lowest sales. Only sold if the customer actually needed, was honest with the products. Fired too.\n\nManagement really didn't like it when they asked why I had so low sales and I answered *\"I was hired to solve problems, not make new ones\"*", "edited": false, "top_awarded_type": null, "downs": 0, "author_flair_css_class": null, "is_submitter": false, "collapsed": false, "author_flair_richtext": [], "author_patreon_flair": false, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I didn\u2019t however sell them stuff they didn\u2019t need.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Well fuck me sideways, more or less same story here. Highest average solved cases daily, shortest phone calls, made some tools to more quickly and effective find common issues... But lowest sales. Only sold if the customer actually needed, was honest with the products. Fired too.&lt;/p&gt;\n\n&lt;p&gt;Management really didn&amp;#39;t like it when they asked why I had so low sales and I answered &lt;em&gt;&amp;quot;I was hired to solve problems, not make new ones&amp;quot;&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;", "gildings": {}, "collapsed_reason": null, "distinguished": null, "associated_award": null, "stickied": false, "author_premium": false, "can_gild": true, "link_id": "t3_11rtvwi", "unrepliable_reason": null, "author_flair_text_color": null, "score_hidden": false, "permalink": "/r/comics/comments/11rtvwi/tech_support/jcd9ohl/", "subreddit_type": "public", "link_permalink": "https://www.reddit.com/r/comics/comments/11rtvwi/tech_support/", "name": "t1_jcd9ohl", "author_flair_template_id": null, "subreddit_name_prefixed": "r/comics", "author_flair_text": null, "treatment_tags": [], "created": 1678925795.0, "created_utc": 1678925795.0, "awarders": [], "all_awardings": [], "locked": false, "author_flair_background_color": null, "collapsed_because_crowd_control": null, "mod_reports": [], "quarantine": false, "mod_note": null, "link_url": "https://i.redd.it/1viv2n654wna1.png"}}], "before": null}}